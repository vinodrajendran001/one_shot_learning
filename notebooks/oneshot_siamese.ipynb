{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import walk\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from PIL import Image\n",
    "import cv2\n",
    "from torchsummary import summary\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating the pairs of images for inputs, same character label = 1, vice versa\n",
    "class OmniglotDataset(Dataset):\n",
    "    def __init__(self, categories, root_dir, setSize, transform=None):\n",
    "        self.categories = categories\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.setSize = setSize\n",
    "    def __len__(self):\n",
    "        return self.setSize\n",
    "    def __getitem__(self, idx):\n",
    "        img1 = None\n",
    "        img2 = None\n",
    "        label = None\n",
    "        if idx % 2 == 0: \n",
    "            # select the same character for both images\n",
    "            category = random.choice(categories)\n",
    "            character = random.choice(category[1])\n",
    "            imgDir = root_dir + category[0] + '/' + character\n",
    "            img1Name = random.choice(os.listdir(imgDir))\n",
    "            img2Name = random.choice(os.listdir(imgDir))\n",
    "            img1 = Image.open(imgDir + '/' + img1Name)\n",
    "            img2 = Image.open(imgDir + '/' + img2Name)\n",
    "            label = 1.0\n",
    "        else: \n",
    "            # select a different character for both images\n",
    "            category1, category2 = random.choice(categories), random.choice(categories)\n",
    "            category1, category2 = random.choice(categories), random.choice(categories)\n",
    "            character1, character2 = random.choice(category1[1]), random.choice(category2[1])\n",
    "            imgDir1, imgDir2 = root_dir + category1[0] + '/' + character1, root_dir + category2[0] + '/' + character2\n",
    "            img1Name = random.choice(os.listdir(imgDir1))\n",
    "            img2Name = random.choice(os.listdir(imgDir2))\n",
    "            while img1Name == img2Name:\n",
    "                img2Name = random.choice(os.listdir(imgDir2))\n",
    "            label = 0.0\n",
    "            img1 = Image.open(imgDir1 + '/' + img1Name)\n",
    "            img2 = Image.open(imgDir2 + '/' + img2Name)\n",
    "        if self.transform:\n",
    "            img1 = self.transform(img1)\n",
    "            img2 = self.transform(img2)\n",
    "        return img1, img2, torch.from_numpy(np.array([label], dtype=np.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creates n-way one shot learning evaluation\n",
    "class NWayOneShotEvalSet(Dataset):\n",
    "    def __init__(self, categories, root_dir, setSize, numWay, transform=None):\n",
    "        self.categories = categories\n",
    "        self.root_dir = root_dir\n",
    "        self.setSize = setSize\n",
    "        self.numWay = numWay\n",
    "        self.transform = transform\n",
    "    def __len__(self):\n",
    "        return self.setSize\n",
    "    def __getitem__(self, idx):\n",
    "        # find one main image\n",
    "        category = random.choice(categories)\n",
    "        character = random.choice(category[1])\n",
    "        imgDir = root_dir + category[0] + '/' + character\n",
    "        imgName = random.choice(os.listdir(imgDir))\n",
    "        mainImg = Image.open(imgDir + '/' + imgName)\n",
    "        if self.transform:\n",
    "            mainImg = self.transform(mainImg)\n",
    "        \n",
    "        # find n numbers of distinct images, 1 in the same set as the main\n",
    "        testSet = []\n",
    "        label = np.random.randint(self.numWay)\n",
    "        for i in range(self.numWay):\n",
    "            testImgDir = imgDir\n",
    "            testImgName = ''\n",
    "            if i == label:\n",
    "                testImgName = random.choice(os.listdir(imgDir))\n",
    "            else:\n",
    "                testCategory = random.choice(categories)\n",
    "                testCharacter = random.choice(testCategory[1])\n",
    "                testImgDir = root_dir + testCategory[0] + '/' + testCharacter\n",
    "                while testImgDir == imgDir:\n",
    "                    testImgDir = root_dir + testCategory[0] + '/' + testCharacter\n",
    "                testImgName = random.choice(os.listdir(testImgDir))\n",
    "            testImg = Image.open(testImgDir + '/' + testImgName)\n",
    "            if self.transform:\n",
    "                testImg = self.transform(testImg)\n",
    "            testSet.append(testImg)\n",
    "        return mainImg, testSet, torch.from_numpy(np.array([label], dtype = int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting the root directories and categories of the images\n",
    "root_dir = '../data/raw/images_evaluation/'\n",
    "categories = [[folder, os.listdir(root_dir + folder)] for folder in os.listdir(root_dir)  if not folder.startswith('.') ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose a training dataset size and further divide it into train and validation set 80:20\n",
    "dataSize = 10000 # self-defined dataset size\n",
    "TRAIN_PCT = 0.8 # percentage of entire dataset for training\n",
    "train_size = int(dataSize * TRAIN_PCT)\n",
    "val_size = dataSize - train_size\n",
    "\n",
    "transformations = transforms.Compose(\n",
    "    [transforms.ToTensor()]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "omniglotDataset = OmniglotDataset(categories, root_dir, dataSize, transformations)\n",
    "train_set, val_set = random_split(omniglotDataset, [train_size, val_size])\n",
    "train_loader = torch.utils.data.DataLoader(train_set, batch_size=128, num_workers=0)\n",
    "val_loader = torch.utils.data.DataLoader(val_set, batch_size=1, num_workers=0, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the test set for final testing\n",
    "testSize = 5000 \n",
    "numWay = 20\n",
    "test_set = NWayOneShotEvalSet(categories, root_dir, testSize, numWay, transformations)\n",
    "test_loader = torch.utils.data.DataLoader(test_set, batch_size = 1, num_workers = 0, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        # Koch et al.\n",
    "        # Conv2d(input_channels, output_channels, kernel_size)\n",
    "        self.conv1 = nn.Conv2d(1, 64, 10) \n",
    "        self.conv2 = nn.Conv2d(64, 128, 7)  \n",
    "        self.conv3 = nn.Conv2d(128, 128, 4)\n",
    "        self.conv4 = nn.Conv2d(128, 256, 4)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.bn2 = nn.BatchNorm2d(128)\n",
    "        self.bn3 = nn.BatchNorm2d(128)\n",
    "        self.bn4 = nn.BatchNorm2d(256)\n",
    "        self.dropout1 = nn.Dropout(0.1)\n",
    "        self.dropout2 = nn.Dropout(0.5)\n",
    "        self.fc1 = nn.Linear(256 * 6 * 6, 4096)\n",
    "        self.fcOut = nn.Linear(4096, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def convs(self, x):\n",
    "\n",
    "        # Koch et al.\n",
    "        # out_dim = in_dim - kernel_size + 1  \n",
    "        #1, 105, 105\n",
    "        x = F.relu(self.bn1(self.conv1(x)))\n",
    "        # 64, 96, 96\n",
    "        x = F.max_pool2d(x, (2,2))\n",
    "        # 64, 48, 48\n",
    "        x = F.relu(self.bn2(self.conv2(x)))\n",
    "        # 128, 42, 42\n",
    "        x = F.max_pool2d(x, (2,2))\n",
    "        # 128, 21, 21\n",
    "        x = F.relu(self.bn3(self.conv3(x)))\n",
    "        # 128, 18, 18\n",
    "        x = F.max_pool2d(x, (2,2))\n",
    "        # 128, 9, 9\n",
    "        x = F.relu(self.bn4(self.conv4(x)))\n",
    "        # 256, 6, 6\n",
    "        return x\n",
    "\n",
    "    def forward(self, x1, x2):\n",
    "        x1 = self.convs(x1)\n",
    "\n",
    "        # Koch et al.\n",
    "        x1 = x1.view(-1, 256 * 6 * 6)\n",
    "        x1 = self.sigmoid(self.fc1(x1))\n",
    "       \n",
    "        x2 = self.convs(x2)\n",
    "\n",
    "        # Koch et al.\n",
    "        x2 = x2.view(-1, 256 * 6 * 6)\n",
    "        x2 = self.sigmoid(self.fc1(x2))\n",
    "        x = torch.abs(x1 - x2)\n",
    "        x = self.fcOut(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating the original network and couting the paramenters of different networks\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "siameseBaseLine = Net()\n",
    "siameseBaseLine = siameseBaseLine.to(device)\n",
    "\n",
    "def count_parameters(model):\n",
    "    temp = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    print(f'The model architecture:\\n\\n', model)\n",
    "    print(f'\\nThe model has {temp:,} trainable parameters')\n",
    "    \n",
    "count_parameters(siameseBaseLine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving and loading checkpoint mechanisms\n",
    "def save_checkpoint(save_path, model, optimizer, val_loss):\n",
    "    if save_path==None:\n",
    "        return\n",
    "    save_path = save_path \n",
    "    state_dict = {'model_state_dict': model.state_dict(),\n",
    "                  'optimizer_state_dict': optimizer.state_dict(),\n",
    "                  'val_loss': val_loss}\n",
    "\n",
    "    torch.save(state_dict, save_path)\n",
    "\n",
    "    print(f'Model saved to ==> {save_path}')\n",
    "\n",
    "def load_checkpoint(model, optimizer):\n",
    "    save_path = f'siameseNet-batchnorm50.pt'\n",
    "    state_dict = torch.load(save_path)\n",
    "    model.load_state_dict(state_dict['model_state_dict'])\n",
    "    optimizer.load_state_dict(state_dict['optimizer_state_dict'])\n",
    "    val_loss = state_dict['val_loss']\n",
    "    print(f'Model loaded from <== {save_path}')\n",
    "    \n",
    "    return val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training and validation after every epoch\n",
    "def train(model, train_loader, val_loader, num_epochs, criterion, save_name):\n",
    "    best_val_loss = float(\"Inf\") \n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    cur_step = 0\n",
    "    for epoch in range(num_epochs):\n",
    "        running_loss = 0.0\n",
    "        model.train()\n",
    "        print(\"Starting epoch \" + str(epoch+1))\n",
    "        for img1, img2, labels in train_loader:\n",
    "            \n",
    "            # Forward\n",
    "            img1 = img1.to(device)\n",
    "            img2 = img2.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(img1, img2)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            # Backward and optimize\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "\n",
    "        avg_train_loss = running_loss / len(train_loader)\n",
    "        train_losses.append(avg_train_loss)\n",
    "        \n",
    "        val_running_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            model.eval()\n",
    "            for img1, img2, labels in val_loader:\n",
    "                img1 = img1.to(device)\n",
    "                img2 = img2.to(device)\n",
    "                labels = labels.to(device)\n",
    "                outputs = model(img1, img2)\n",
    "                loss = criterion(outputs, labels)\n",
    "                val_running_loss += loss.item()\n",
    "        avg_val_loss = val_running_loss / len(val_loader)\n",
    "        val_losses.append(avg_val_loss)\n",
    "        \n",
    "        print('Epoch [{}/{}],Train Loss: {:.4f}, Valid Loss: {:.8f}'\n",
    "            .format(epoch+1, num_epochs, avg_train_loss, avg_val_loss))\n",
    "        if avg_val_loss < best_val_loss:\n",
    "            best_val_loss = avg_val_loss\n",
    "            save_checkpoint(save_name, model, optimizer, best_val_loss)\n",
    "    \n",
    "    print(\"Finished Training\")  \n",
    "    return train_losses, val_losses  \n",
    "\n",
    "# evaluation metrics\n",
    "def eval(model, test_loader):\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        correct = 0\n",
    "        print('Starting Iteration')\n",
    "        count = 0\n",
    "        for mainImg, imgSets, label in test_loader:\n",
    "            mainImg = mainImg.to(device)\n",
    "            predVal = 0\n",
    "            pred = -1\n",
    "            for i, testImg in enumerate(imgSets):\n",
    "                testImg = testImg.to(device)\n",
    "                output = model(mainImg, testImg)\n",
    "                if output > predVal:\n",
    "                    pred = i\n",
    "                    predVal = output\n",
    "            label = label.to(device)\n",
    "            if pred == label:\n",
    "                correct += 1\n",
    "            count += 1\n",
    "            if count % 20 == 0:\n",
    "                print(\"Current Count is: {}\".format(count))\n",
    "                print('Accuracy on n way: {}'.format(correct/count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# actual training\n",
    "import torch.optim as optim\n",
    "\n",
    "optimizer = optim.Adam(siameseBaseLine.parameters(), lr = 0.0006)\n",
    "num_epochs = 2\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "save_path = '../models/siameseNet-batchnorm50.pt'\n",
    "train_losses, val_losses = train(siameseBaseLine, train_loader, val_loader, num_epochs, criterion, save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation on previously saved models\n",
    "import torch.optim as optim\n",
    "load_model = Net().to(device)\n",
    "load_optimizer = optim.Adam(load_model.parameters(), lr=0.0006)\n",
    "\n",
    "\n",
    "num_epochs = 10\n",
    "eval_every = 1000\n",
    "total_step = len(train_loader)*num_epochs\n",
    "best_val_loss = load_checkpoint(load_model, load_optimizer)\n",
    "\n",
    "print(best_val_loss)\n",
    "eval(load_model, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plotting of training and validation loss\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss')\n",
    "plt.plot(train_losses, label='Train Loss')\n",
    "plt.plot(val_losses, label=\"Validation Loss\")\n",
    "plt.legend(bbox_to_anchor=(1.05, 1.0), loc='upper left')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:conda-oneshot] *",
   "language": "python",
   "name": "conda-env-conda-oneshot-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
