{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "oneshot_siamese.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "jiaN3NOnJMRa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "53f7455b-fda1-4f8d-eaee-7d7ded782869"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ubcEiuB7Jo8_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 399
        },
        "outputId": "b19a137d-dc9c-4773-a4d1-5e158702e42d"
      },
      "source": [
        "!nvidia-smi\n",
        "%cd /content/drive/My Drive/Colab Notebooks/one_shot_learning/\n",
        "!ls"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sun Sep 20 00:19:38 2020       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 450.66       Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   40C    P8     9W /  70W |      0MiB / 15079MiB |      0%      Default |\n",
            "|                               |                      |                 ERR! |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n",
            "/content/drive/My Drive/Colab Notebooks/one_shot_learning\n",
            "images_evaluation  oneshot_siamese.ipynb  siameseNet-batchnorm50.pt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L1uPdes9KX4R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from os import walk\n",
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "from PIL import Image\n",
        "import cv2\n",
        "from torchsummary import summary\n",
        "from torch.utils.data import Dataset, DataLoader, random_split\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import random"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fDgtfpTtK8AW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# setting the root directories and categories of the images\n",
        "# root_dir = './images_background/'\n",
        "root_dir = './images_evaluation/'\n",
        "categories = [[folder, os.listdir(root_dir + folder)] for folder in os.listdir(root_dir)  if not folder.startswith('.') ]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "89QNEAwNLNDr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# creating the pairs of images for inputs, same character label = 1, vice versa\n",
        "class OmniglotDataset(Dataset):\n",
        "    def __init__(self, categories, root_dir, setSize, transform=None):\n",
        "        self.categories = categories\n",
        "        self.root_dir = root_dir\n",
        "        self.transform = transform\n",
        "        self.setSize = setSize\n",
        "    def __len__(self):\n",
        "        return self.setSize\n",
        "    def __getitem__(self, idx):\n",
        "        img1 = None\n",
        "        img2 = None\n",
        "        label = None\n",
        "        if idx % 2 == 0: # select the same character for both images\n",
        "            category = random.choice(categories)\n",
        "            character = random.choice(category[1])\n",
        "            imgDir = root_dir + category[0] + '/' + character\n",
        "            img1Name = random.choice(os.listdir(imgDir))\n",
        "            img2Name = random.choice(os.listdir(imgDir))\n",
        "            img1 = Image.open(imgDir + '/' + img1Name)\n",
        "            img2 = Image.open(imgDir + '/' + img2Name)\n",
        "            # print(imgDir+'/'+img1Name)\n",
        "            # print(imgDir+'/'+img2Name)\n",
        "            label = 1.0\n",
        "        else: # select a different character for both images\n",
        "            category1, category2 = random.choice(categories), random.choice(categories)\n",
        "            category1, category2 = random.choice(categories), random.choice(categories)\n",
        "            character1, character2 = random.choice(category1[1]), random.choice(category2[1])\n",
        "            imgDir1, imgDir2 = root_dir + category1[0] + '/' + character1, root_dir + category2[0] + '/' + character2\n",
        "            img1Name = random.choice(os.listdir(imgDir1))\n",
        "            img2Name = random.choice(os.listdir(imgDir2))\n",
        "            while img1Name == img2Name:\n",
        "                img2Name = random.choice(os.listdir(imgDir2))\n",
        "            label = 0.0\n",
        "            img1 = Image.open(imgDir1 + '/' + img1Name)\n",
        "            img2 = Image.open(imgDir2 + '/' + img2Name)\n",
        "#         plt.imshow(img1)\n",
        "        if self.transform:\n",
        "            img1 = self.transform(img1)\n",
        "            img2 = self.transform(img2)\n",
        "        return img1, img2, torch.from_numpy(np.array([label], dtype=np.float32))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7nh2toMVLZOh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# creates n-way one shot learning evaluation\n",
        "class NWayOneShotEvalSet(Dataset):\n",
        "    def __init__(self, categories, root_dir, setSize, numWay, transform=None):\n",
        "        self.categories = categories\n",
        "        self.root_dir = root_dir\n",
        "        self.setSize = setSize\n",
        "        self.numWay = numWay\n",
        "        self.transform = transform\n",
        "    def __len__(self):\n",
        "        return self.setSize\n",
        "    def __getitem__(self, idx):\n",
        "        # find one main image\n",
        "        category = random.choice(categories)\n",
        "        character = random.choice(category[1])\n",
        "        imgDir = root_dir + category[0] + '/' + character\n",
        "        imgName = random.choice(os.listdir(imgDir))\n",
        "        mainImg = Image.open(imgDir + '/' + imgName)\n",
        "        # print(imgDir + '/' + imgName)\n",
        "        if self.transform:\n",
        "            mainImg = self.transform(mainImg)\n",
        "        \n",
        "        # find n numbers of distinct images, 1 in the same set as the main\n",
        "        testSet = []\n",
        "        label = np.random.randint(self.numWay)\n",
        "        for i in range(self.numWay):\n",
        "            testImgDir = imgDir\n",
        "            testImgName = ''\n",
        "            if i == label:\n",
        "                testImgName = random.choice(os.listdir(imgDir))\n",
        "            else:\n",
        "                testCategory = random.choice(categories)\n",
        "                testCharacter = random.choice(testCategory[1])\n",
        "                testImgDir = root_dir + testCategory[0] + '/' + testCharacter\n",
        "                while testImgDir == imgDir:\n",
        "                    testImgDir = root_dir + testCategory[0] + '/' + testCharacter\n",
        "                testImgName = random.choice(os.listdir(testImgDir))\n",
        "            testImg = Image.open(testImgDir + '/' + testImgName)\n",
        "            if self.transform:\n",
        "                testImg = self.transform(testImg)\n",
        "            testSet.append(testImg)\n",
        "        # plt.imshow()\n",
        "        return mainImg, testSet, torch.from_numpy(np.array([label], dtype = int))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aCG61MM2Lb5h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# choose a training dataset size and further divide it into train and validation set 80:20\n",
        "dataSize = 10000 # self-defined dataset size\n",
        "TRAIN_PCT = 0.8 # percentage of entire dataset for training\n",
        "train_size = int(dataSize * TRAIN_PCT)\n",
        "val_size = dataSize - train_size\n",
        "\n",
        "transformations = transforms.Compose(\n",
        "    [transforms.ToTensor()]) \n",
        "\n",
        "omniglotDataset = OmniglotDataset(categories, root_dir, dataSize, transformations)\n",
        "train_set, val_set = random_split(omniglotDataset, [train_size, val_size])\n",
        "train_loader = torch.utils.data.DataLoader(train_set, batch_size=128, num_workers=16)\n",
        "val_loader = torch.utils.data.DataLoader(val_set, batch_size=1, num_workers=16, shuffle=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OJfwVivgLhOq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# create the test set for final testing\n",
        "testSize = 5000 \n",
        "numWay = 20\n",
        "test_set = NWayOneShotEvalSet(categories, root_dir, testSize, numWay, transformations)\n",
        "test_loader = torch.utils.data.DataLoader(test_set, batch_size = 1, num_workers = 2, shuffle=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xG3EsxKbLkcT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VESNQjO5LoFs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Different network structures, the commented out are the different experimenting structures\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        \n",
        "        # Koch et al.\n",
        "        # Conv2d(input_channels, output_channels, kernel_size)\n",
        "        self.conv1 = nn.Conv2d(1, 64, 10) \n",
        "        self.conv2 = nn.Conv2d(64, 128, 7)  \n",
        "        self.conv3 = nn.Conv2d(128, 128, 4)\n",
        "        self.conv4 = nn.Conv2d(128, 256, 4)\n",
        "        self.bn1 = nn.BatchNorm2d(64)\n",
        "        self.bn2 = nn.BatchNorm2d(128)\n",
        "        self.bn3 = nn.BatchNorm2d(128)\n",
        "        self.bn4 = nn.BatchNorm2d(256)\n",
        "        self.dropout1 = nn.Dropout(0.1)\n",
        "        self.dropout2 = nn.Dropout(0.5)\n",
        "        self.fc1 = nn.Linear(256 * 6 * 6, 4096)\n",
        "        self.fcOut = nn.Linear(4096, 1)\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "    \n",
        "    def convs(self, x):\n",
        "\n",
        "        # Koch et al.\n",
        "        # out_dim = in_dim - kernel_size + 1  \n",
        "        #1, 105, 105\n",
        "        x = F.relu(self.bn1(self.conv1(x)))\n",
        "        # 64, 96, 96\n",
        "        x = F.max_pool2d(x, (2,2))\n",
        "        # 64, 48, 48\n",
        "        x = F.relu(self.bn2(self.conv2(x)))\n",
        "        # 128, 42, 42\n",
        "        x = F.max_pool2d(x, (2,2))\n",
        "        # 128, 21, 21\n",
        "        x = F.relu(self.bn3(self.conv3(x)))\n",
        "        # 128, 18, 18\n",
        "        x = F.max_pool2d(x, (2,2))\n",
        "        # 128, 9, 9\n",
        "        x = F.relu(self.bn4(self.conv4(x)))\n",
        "        # 256, 6, 6\n",
        "        return x\n",
        "\n",
        "\n",
        "    def forward(self, x1, x2):\n",
        "        x1 = self.convs(x1)\n",
        "\n",
        "        # Koch et al.\n",
        "        x1 = x1.view(-1, 256 * 6 * 6)\n",
        "        x1 = self.sigmoid(self.fc1(x1))\n",
        "        \n",
        "        x2 = self.convs(x2)\n",
        "\n",
        "        # Koch et al.\n",
        "        x2 = x2.view(-1, 256 * 6 * 6)\n",
        "        x2 = self.sigmoid(self.fc1(x2))\n",
        "\n",
        "        x = torch.abs(x1 - x2)\n",
        "        x = self.fcOut(x)\n",
        "        return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hR914ERMLrZM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 347
        },
        "outputId": "f122fdbb-0c84-4d1e-b790-7ab4f4f7c3e3"
      },
      "source": [
        "#creating the original network and couting the paramenters of different networks\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "siameseBaseLine = Net()\n",
        "siameseBaseLine = siameseBaseLine.to(device)\n",
        "\n",
        "def count_parameters(model):\n",
        "    temp = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "    print(f'The model architecture:\\n\\n', model)\n",
        "    print(f'\\nThe model has {temp:,} trainable parameters')\n",
        "    \n",
        "count_parameters(siameseBaseLine)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The model architecture:\n",
            "\n",
            " Net(\n",
            "  (conv1): Conv2d(1, 64, kernel_size=(10, 10), stride=(1, 1))\n",
            "  (conv2): Conv2d(64, 128, kernel_size=(7, 7), stride=(1, 1))\n",
            "  (conv3): Conv2d(128, 128, kernel_size=(4, 4), stride=(1, 1))\n",
            "  (conv4): Conv2d(128, 256, kernel_size=(4, 4), stride=(1, 1))\n",
            "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (bn3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (bn4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (dropout1): Dropout(p=0.1, inplace=False)\n",
            "  (dropout2): Dropout(p=0.5, inplace=False)\n",
            "  (fc1): Linear(in_features=9216, out_features=4096, bias=True)\n",
            "  (fcOut): Linear(in_features=4096, out_features=1, bias=True)\n",
            "  (sigmoid): Sigmoid()\n",
            ")\n",
            "\n",
            "The model has 38,952,897 trainable parameters\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XiN_K2fbLxi1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# saving and loading checkpoint mechanisms\n",
        "def save_checkpoint(save_path, model, optimizer, val_loss):\n",
        "    if save_path==None:\n",
        "        return\n",
        "    save_path = save_path \n",
        "    state_dict = {'model_state_dict': model.state_dict(),\n",
        "                  'optimizer_state_dict': optimizer.state_dict(),\n",
        "                  'val_loss': val_loss}\n",
        "\n",
        "    torch.save(state_dict, save_path)\n",
        "\n",
        "    print(f'Model saved to ==> {save_path}')\n",
        "\n",
        "def load_checkpoint(model, optimizer):\n",
        "    save_path = f'siameseNet-batchnorm50.pt'\n",
        "    state_dict = torch.load(save_path)\n",
        "    model.load_state_dict(state_dict['model_state_dict'])\n",
        "    optimizer.load_state_dict(state_dict['optimizer_state_dict'])\n",
        "    val_loss = state_dict['val_loss']\n",
        "    print(f'Model loaded from <== {save_path}')\n",
        "    \n",
        "    return val_loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "53iy0BuLL00Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# training and validation after every epoch\n",
        "def train(model, train_loader, val_loader, num_epochs, criterion, save_name):\n",
        "    best_val_loss = float(\"Inf\") \n",
        "    train_losses = []\n",
        "    val_losses = []\n",
        "    cur_step = 0\n",
        "    for epoch in range(num_epochs):\n",
        "        running_loss = 0.0\n",
        "        model.train()\n",
        "        print(\"Starting epoch \" + str(epoch+1))\n",
        "        for img1, img2, labels in train_loader:\n",
        "            \n",
        "            # Forward\n",
        "            img1 = img1.to(device)\n",
        "            img2 = img2.to(device)\n",
        "            labels = labels.to(device)\n",
        "            outputs = model(img1, img2)\n",
        "            loss = criterion(outputs, labels)\n",
        "            \n",
        "            # Backward and optimize\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            running_loss += loss.item()\n",
        "\n",
        "        avg_train_loss = running_loss / len(train_loader)\n",
        "        train_losses.append(avg_train_loss)\n",
        "        \n",
        "        val_running_loss = 0.0\n",
        "        with torch.no_grad():\n",
        "            model.eval()\n",
        "            for img1, img2, labels in val_loader:\n",
        "                img1 = img1.to(device)\n",
        "                img2 = img2.to(device)\n",
        "                labels = labels.to(device)\n",
        "                outputs = model(img1, img2)\n",
        "                loss = criterion(outputs, labels)\n",
        "                val_running_loss += loss.item()\n",
        "        avg_val_loss = val_running_loss / len(val_loader)\n",
        "        val_losses.append(avg_val_loss)\n",
        "        \n",
        "        print('Epoch [{}/{}],Train Loss: {:.4f}, Valid Loss: {:.8f}'\n",
        "            .format(epoch+1, num_epochs, avg_train_loss, avg_val_loss))\n",
        "        if avg_val_loss < best_val_loss:\n",
        "            best_val_loss = avg_val_loss\n",
        "            save_checkpoint(save_name, model, optimizer, best_val_loss)\n",
        "    \n",
        "    print(\"Finished Training\")  \n",
        "    return train_losses, val_losses  \n",
        "\n",
        "# evaluation metrics\n",
        "def eval(model, test_loader):\n",
        "    with torch.no_grad():\n",
        "        model.eval()\n",
        "        correct = 0\n",
        "        print('Starting Iteration')\n",
        "        count = 0\n",
        "        for mainImg, imgSets, label in test_loader:\n",
        "            mainImg = mainImg.to(device)\n",
        "            predVal = 0\n",
        "            pred = -1\n",
        "            for i, testImg in enumerate(imgSets):\n",
        "                testImg = testImg.to(device)\n",
        "                output = model(mainImg, testImg)\n",
        "                if output > predVal:\n",
        "                    pred = i\n",
        "                    predVal = output\n",
        "            label = label.to(device)\n",
        "            if pred == label:\n",
        "                correct += 1\n",
        "            count += 1\n",
        "            if count % 20 == 0:\n",
        "                print(\"Current Count is: {}\".format(count))\n",
        "                print('Accuracy on n way: {}'.format(correct/count))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wj0qUOCEL4_p",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "b85e2abe-403f-4fee-b5b7-719ef137d5a6"
      },
      "source": [
        "# actual training\n",
        "import torch.optim as optim\n",
        "\n",
        "optimizer = optim.Adam(siameseBaseLine.parameters(), lr = 0.0006)\n",
        "num_epochs = 50\n",
        "criterion = nn.BCEWithLogitsLoss()\n",
        "save_path = 'siameseNet-batchnorm50.pt'\n",
        "train_losses, val_losses = train(siameseBaseLine, train_loader, val_loader, num_epochs, criterion, save_path)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Starting epoch 1\n",
            "Epoch [1/50],Train Loss: 0.5350, Valid Loss: 0.47470690\n",
            "Model saved to ==> siameseNet-batchnorm50.pt\n",
            "Starting epoch 2\n",
            "Epoch [2/50],Train Loss: 0.4280, Valid Loss: 0.38181303\n",
            "Model saved to ==> siameseNet-batchnorm50.pt\n",
            "Starting epoch 3\n",
            "Epoch [3/50],Train Loss: 0.3695, Valid Loss: 0.33729465\n",
            "Model saved to ==> siameseNet-batchnorm50.pt\n",
            "Starting epoch 4\n",
            "Epoch [4/50],Train Loss: 0.3279, Valid Loss: 0.31303892\n",
            "Model saved to ==> siameseNet-batchnorm50.pt\n",
            "Starting epoch 5\n",
            "Epoch [5/50],Train Loss: 0.3061, Valid Loss: 0.30648287\n",
            "Model saved to ==> siameseNet-batchnorm50.pt\n",
            "Starting epoch 6\n",
            "Epoch [6/50],Train Loss: 0.2921, Valid Loss: 0.28454563\n",
            "Model saved to ==> siameseNet-batchnorm50.pt\n",
            "Starting epoch 7\n",
            "Epoch [7/50],Train Loss: 0.2783, Valid Loss: 0.24636494\n",
            "Model saved to ==> siameseNet-batchnorm50.pt\n",
            "Starting epoch 8\n",
            "Epoch [8/50],Train Loss: 0.2595, Valid Loss: 0.24200200\n",
            "Model saved to ==> siameseNet-batchnorm50.pt\n",
            "Starting epoch 9\n",
            "Epoch [9/50],Train Loss: 0.2448, Valid Loss: 0.25298020\n",
            "Starting epoch 10\n",
            "Epoch [10/50],Train Loss: 0.2462, Valid Loss: 0.26437291\n",
            "Starting epoch 11\n",
            "Epoch [11/50],Train Loss: 0.2385, Valid Loss: 0.23797455\n",
            "Model saved to ==> siameseNet-batchnorm50.pt\n",
            "Starting epoch 12\n",
            "Epoch [12/50],Train Loss: 0.2276, Valid Loss: 0.23560047\n",
            "Model saved to ==> siameseNet-batchnorm50.pt\n",
            "Starting epoch 13\n",
            "Epoch [13/50],Train Loss: 0.2231, Valid Loss: 0.23436914\n",
            "Model saved to ==> siameseNet-batchnorm50.pt\n",
            "Starting epoch 14\n",
            "Epoch [14/50],Train Loss: 0.2117, Valid Loss: 0.20203247\n",
            "Model saved to ==> siameseNet-batchnorm50.pt\n",
            "Starting epoch 15\n",
            "Epoch [15/50],Train Loss: 0.2182, Valid Loss: 0.20114114\n",
            "Model saved to ==> siameseNet-batchnorm50.pt\n",
            "Starting epoch 16\n",
            "Epoch [16/50],Train Loss: 0.2056, Valid Loss: 0.20301803\n",
            "Starting epoch 17\n",
            "Epoch [17/50],Train Loss: 0.1967, Valid Loss: 0.19696505\n",
            "Model saved to ==> siameseNet-batchnorm50.pt\n",
            "Starting epoch 18\n",
            "Epoch [18/50],Train Loss: 0.2015, Valid Loss: 0.19548752\n",
            "Model saved to ==> siameseNet-batchnorm50.pt\n",
            "Starting epoch 19\n",
            "Epoch [19/50],Train Loss: 0.1943, Valid Loss: 0.18487779\n",
            "Model saved to ==> siameseNet-batchnorm50.pt\n",
            "Starting epoch 20\n",
            "Epoch [20/50],Train Loss: 0.1861, Valid Loss: 0.17584543\n",
            "Model saved to ==> siameseNet-batchnorm50.pt\n",
            "Starting epoch 21\n",
            "Epoch [21/50],Train Loss: 0.1883, Valid Loss: 0.17304853\n",
            "Model saved to ==> siameseNet-batchnorm50.pt\n",
            "Starting epoch 22\n",
            "Epoch [22/50],Train Loss: 0.1838, Valid Loss: 0.16432928\n",
            "Model saved to ==> siameseNet-batchnorm50.pt\n",
            "Starting epoch 23\n",
            "Epoch [23/50],Train Loss: 0.1732, Valid Loss: 0.16751662\n",
            "Starting epoch 24\n",
            "Epoch [24/50],Train Loss: 0.1769, Valid Loss: 0.16797046\n",
            "Starting epoch 25\n",
            "Epoch [25/50],Train Loss: 0.1697, Valid Loss: 0.17113214\n",
            "Starting epoch 26\n",
            "Epoch [26/50],Train Loss: 0.1675, Valid Loss: 0.15019794\n",
            "Model saved to ==> siameseNet-batchnorm50.pt\n",
            "Starting epoch 27\n",
            "Epoch [27/50],Train Loss: 0.1642, Valid Loss: 0.16867505\n",
            "Starting epoch 28\n",
            "Epoch [28/50],Train Loss: 0.1658, Valid Loss: 0.14039145\n",
            "Model saved to ==> siameseNet-batchnorm50.pt\n",
            "Starting epoch 29\n",
            "Epoch [29/50],Train Loss: 0.1605, Valid Loss: 0.12959231\n",
            "Model saved to ==> siameseNet-batchnorm50.pt\n",
            "Starting epoch 30\n",
            "Epoch [30/50],Train Loss: 0.1581, Valid Loss: 0.15109588\n",
            "Starting epoch 31\n",
            "Epoch [31/50],Train Loss: 0.1496, Valid Loss: 0.14863236\n",
            "Starting epoch 32\n",
            "Epoch [32/50],Train Loss: 0.1444, Valid Loss: 0.13216972\n",
            "Starting epoch 33\n",
            "Epoch [33/50],Train Loss: 0.1475, Valid Loss: 0.14810770\n",
            "Starting epoch 34\n",
            "Epoch [34/50],Train Loss: 0.1480, Valid Loss: 0.13724976\n",
            "Starting epoch 35\n",
            "Epoch [35/50],Train Loss: 0.1453, Valid Loss: 0.16015764\n",
            "Starting epoch 36\n",
            "Epoch [36/50],Train Loss: 0.1385, Valid Loss: 0.14096234\n",
            "Starting epoch 37\n",
            "Epoch [37/50],Train Loss: 0.1382, Valid Loss: 0.12584610\n",
            "Model saved to ==> siameseNet-batchnorm50.pt\n",
            "Starting epoch 38\n",
            "Epoch [38/50],Train Loss: 0.1311, Valid Loss: 0.11703370\n",
            "Model saved to ==> siameseNet-batchnorm50.pt\n",
            "Starting epoch 39\n",
            "Epoch [39/50],Train Loss: 0.1291, Valid Loss: 0.11944329\n",
            "Starting epoch 40\n",
            "Epoch [40/50],Train Loss: 0.1327, Valid Loss: 0.13596648\n",
            "Starting epoch 41\n",
            "Epoch [41/50],Train Loss: 0.1279, Valid Loss: 0.12464999\n",
            "Starting epoch 42\n",
            "Epoch [42/50],Train Loss: 0.1225, Valid Loss: 0.12500680\n",
            "Starting epoch 43\n",
            "Epoch [43/50],Train Loss: 0.1217, Valid Loss: 0.12317815\n",
            "Starting epoch 44\n",
            "Epoch [44/50],Train Loss: 0.1181, Valid Loss: 0.11120184\n",
            "Model saved to ==> siameseNet-batchnorm50.pt\n",
            "Starting epoch 45\n",
            "Epoch [45/50],Train Loss: 0.1227, Valid Loss: 0.11453932\n",
            "Starting epoch 46\n",
            "Epoch [46/50],Train Loss: 0.1187, Valid Loss: 0.13155115\n",
            "Starting epoch 47\n",
            "Epoch [47/50],Train Loss: 0.1194, Valid Loss: 0.15368960\n",
            "Starting epoch 48\n",
            "Epoch [48/50],Train Loss: 0.1201, Valid Loss: 0.10868552\n",
            "Model saved to ==> siameseNet-batchnorm50.pt\n",
            "Starting epoch 49\n",
            "Epoch [49/50],Train Loss: 0.1165, Valid Loss: 0.15311026\n",
            "Starting epoch 50\n",
            "Epoch [50/50],Train Loss: 0.1180, Valid Loss: 0.09259657\n",
            "Model saved to ==> siameseNet-batchnorm50.pt\n",
            "Finished Training\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2T7eXZI7MVzU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 433
        },
        "outputId": "4bee9fec-633c-4a19-ef55-470975b4f862"
      },
      "source": [
        "# Evaluation on previously saved models\n",
        "import torch.optim as optim\n",
        "load_model = Net().to(device)\n",
        "load_optimizer = optim.Adam(load_model.parameters(), lr=0.0006)\n",
        "\n",
        "\n",
        "num_epochs = 5\n",
        "eval_every = 10\n",
        "total_step = len(train_loader)*num_epochs\n",
        "best_val_loss = load_checkpoint(load_model, load_optimizer)\n",
        "\n",
        "print(best_val_loss)\n",
        "eval(load_model, test_loader)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model loaded from <== siameseNet-batchnorm50.pt\n",
            "0.0925965714615283\n",
            "Starting Iteration\n",
            "Current Count is: 20\n",
            "Accuracy on n way: 1.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-26-46b0bcd8601a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbest_val_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mload_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-13-a38c6dc40203>\u001b[0m in \u001b[0;36meval\u001b[0;34m(model, test_loader)\u001b[0m\n\u001b[1;32m     56\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Starting Iteration'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m         \u001b[0mcount\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mmainImg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimgSets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m             \u001b[0mmainImg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmainImg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m             \u001b[0mpredVal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    361\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    362\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 363\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    364\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    365\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    972\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    973\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shutdown\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 974\u001b[0;31m             \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    975\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    976\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    939\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    940\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 941\u001b[0;31m                 \u001b[0msuccess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    942\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0msuccess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    943\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    777\u001b[0m         \u001b[0;31m#   (bool: whether successfully get data, any: data if successful else None)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    778\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 779\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    780\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    781\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/multiprocessing/queues.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    102\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mblock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m                     \u001b[0mtimeout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeadline\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmonotonic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 104\u001b[0;31m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    105\u001b[0m                         \u001b[0;32mraise\u001b[0m \u001b[0mEmpty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m                 \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/multiprocessing/connection.py\u001b[0m in \u001b[0;36mpoll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    255\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_closed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_readable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 257\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__enter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/multiprocessing/connection.py\u001b[0m in \u001b[0;36m_poll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    412\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    413\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 414\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    415\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    416\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/multiprocessing/connection.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(object_list, timeout)\u001b[0m\n\u001b[1;32m    909\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    910\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 911\u001b[0;31m                 \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    912\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    913\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfileobj\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevents\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/selectors.py\u001b[0m in \u001b[0;36mselect\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    374\u001b[0m             \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    375\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 376\u001b[0;31m                 \u001b[0mfd_event_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    377\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mInterruptedError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    378\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HZFUFj40MZ6Z",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "outputId": "e7eb50f9-202f-427d-d736-5613fc2e1231"
      },
      "source": [
        "#plotting of training and validation loss\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('loss')\n",
        "plt.plot(train_losses, label='Train Loss')\n",
        "plt.plot(val_losses, label=\"Validation Loss\")\n",
        "plt.legend(bbox_to_anchor=(1.05, 1.0), loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}